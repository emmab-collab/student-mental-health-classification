{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet : Détection de la Dépression chez les Étudiants\n",
    "\n",
    "**Objectif** : Prédire si une personne est en dépression à partir de données cliniques et socio-professionnelles.\n",
    "\n",
    "---\n",
    "\n",
    "## Métriques de performance\n",
    "\n",
    "Les classes sont **fortement déséquilibrées** : 18% de cas de dépression, 82% de cas non-dépressifs.\n",
    "\n",
    "- **Recall (sensibilité)** : TP / (TP + FN) → éviter de **manquer un cas positif**  \n",
    "- **Precision (précision)** : TP / (TP + FP) → limiter les **faux positifs**  \n",
    "- **F1-score** → compromis entre précision et recall\n",
    "\n",
    "**Objectif ciblé :** F1 ≈ 0.5 et Recall ≈ 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Ajouter le dossier parent au path pour importer src\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, recall_score\n",
    "\n",
    "# Modules personnalisés\n",
    "from src.preprocessing import set_trainset, preprocessing, test_preprocessing, TARGET_FEATURE\n",
    "from src.modeling import create_models, get_adaboost_hyperparams, optimize_model, get_best_model, create_preprocessor\n",
    "from src.evaluation import evaluation, evaluate_multiple_models, plot_precision_recall_curve, model_final, evaluate_with_threshold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configuration\n",
    "TRAIN_PATH = '../data/train.csv'\n",
    "TEST_PATH = '../data/test.csv'\n",
    "SUBMISSION_PATH = '../data/submission.csv'\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "CV_FOLDS = 4\n",
    "OPTIMAL_THRESHOLD = -0.01\n",
    "\n",
    "print(\"Modules chargés avec succès !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "data = pd.read_csv(TRAIN_PATH)\n",
    "df = data.copy()\n",
    "\n",
    "print(f\"Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Résumé de l'EDA\n",
    "\n",
    "### Principaux insights :\n",
    "\n",
    "- **Classes déséquilibrées** : 18% dépressifs / 82% non-dépressifs  \n",
    "- **Étudiants plus touchés** que les travailleurs  \n",
    "- **Tranche 20-30 ans** particulièrement affectée  \n",
    "- **Pression** académique et professionnelle plus élevée chez les déprimés  \n",
    "- **Hygiène de vie** et Financial Stress semblent influencer la dépression  \n",
    "- **Lien fort** entre idées suicidaires et dépression  \n",
    "- Certaines variables ont >80% de NaN → traitement spécifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la target\n",
    "print(f\"Répartition de {TARGET_FEATURE}:\")\n",
    "print(df[TARGET_FEATURE].value_counts(normalize=True))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "df[TARGET_FEATURE].value_counts().plot(kind='bar', color=['steelblue', 'coral'])\n",
    "plt.title('Distribution de la variable cible (Depression)')\n",
    "plt.xlabel('Depression')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1], ['Non (0)', 'Oui (1)'], rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pre-processing\n",
    "\n",
    "### Stratégie :\n",
    "1. **Train/Test Split** (80/20)\n",
    "2. **Encodage** des variables catégorielles\n",
    "3. **Imputation** des valeurs manquantes\n",
    "4. **Combinaison** des colonnes similaires (Pressure, Satisfaction)\n",
    "\n",
    "--> Dataset réduit à **22353 rows × 16 columns** pour X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train/Test\n",
    "trainset, testset = train_test_split(df, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "print(f\"Trainset shape: {trainset.shape}\")\n",
    "print(f\"Testset shape: {testset.shape}\")\n",
    "\n",
    "print(f\"\\nProportions de {TARGET_FEATURE} dans le trainset:\")\n",
    "print(trainset[TARGET_FEATURE].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le trainset global pour l'encodage\n",
    "set_trainset(trainset)\n",
    "\n",
    "# Preprocessing\n",
    "X_train, y_train = preprocessing(trainset.copy())\n",
    "X_test, y_test = preprocessing(testset.copy())\n",
    "\n",
    "print(f\"\\nX_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aperçu des données preprocessées\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modélisation\n",
    "\n",
    "### Modèles évalués :\n",
    "- **RandomForest**\n",
    "- **AdaBoost**\n",
    "- **SVM**\n",
    "- **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des modèles\n",
    "models = create_models()\n",
    "print(\"Modèles créés:\", list(models.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation de tous les modèles\n",
    "trained_models = evaluate_multiple_models(models, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimisation avec GridSearchCV\n",
    "\n",
    "Basé sur les résultats précédents, **AdaBoost** offre le meilleur compromis.\n",
    "\n",
    "Optimisation des hyperparamètres :\n",
    "- `n_estimators`\n",
    "- `learning_rate`\n",
    "- `algorithm`\n",
    "- `estimator` (DecisionTree avec différents max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV sur AdaBoost\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "preprocessor = create_preprocessor()\n",
    "AdaBoost = make_pipeline(preprocessor, AdaBoostClassifier(random_state=RANDOM_STATE))\n",
    "\n",
    "hyper_params = get_adaboost_hyperparams()\n",
    "print(\"Hyperparamètres à tester:\")\n",
    "for k, v in hyper_params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimisation\n",
    "grid = optimize_model(AdaBoost, X_train, y_train, hyper_params, scoring='recall', cv=CV_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation du meilleur modèle\n",
    "y_pred = grid.predict(X_test)\n",
    "print(\"\\nRapport de classification du meilleur modèle:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbes d'apprentissage du meilleur modèle\n",
    "_ = evaluation(grid.best_estimator_, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Courbe Precision-Recall\n",
    "\n",
    "Permet de trouver le seuil optimal selon nos priorités :\n",
    "- **Priorité au Recall** : éviter de manquer des cas de dépression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe Precision-Recall\n",
    "precision, recall, threshold = plot_precision_recall_curve(grid.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation avec seuil personnalisé\n",
    "print(f\"Évaluation avec threshold = {OPTIMAL_THRESHOLD}:\")\n",
    "metrics = evaluate_with_threshold(grid.best_estimator_, X_test, y_test, threshold=OPTIMAL_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Bilan\n",
    "\n",
    "### Objectif initial :\n",
    "- F1 ≥ 0.5\n",
    "- Recall ≥ 0.7\n",
    "\n",
    "### Résultats obtenus :\n",
    "- **F1 Score : ~0.86**\n",
    "- **Recall : ~0.94**\n",
    "\n",
    "**Objectif largement dépassé !**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Submission (Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle final\n",
    "final_model = get_best_model()\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Modèle final entraîné !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données de test Kaggle\n",
    "df_test = pd.read_csv(TEST_PATH)\n",
    "test_ids = df_test['id'].values\n",
    "\n",
    "print(f\"Test data shape: {df_test.shape}\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing des données de test\n",
    "df_test_processed = test_preprocessing(df_test.copy())\n",
    "\n",
    "print(f\"Test data preprocessed shape: {df_test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions avec seuil\n",
    "predictions = model_final(final_model, df_test_processed, threshold=OPTIMAL_THRESHOLD)\n",
    "predictions = predictions.astype(int)\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"Distribution: {np.bincount(predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le fichier de submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'Depression': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv(SUBMISSION_PATH, index=False)\n",
    "print(f\"Fichier submission.csv créé !\")\n",
    "\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
